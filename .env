# 基础
BACKEND_PORT=8090

# 多模型档位（不包含 OPENAI，避免多出一个选项）
LLM_PROFILES=DEEPSEEK,ZHIPU,PRODUCT,QUANT,VIZ
# 默认档位（不展示 default，本行决定默认选中谁）
LLM_DEFAULT=DEEPSEEK

# 智谱清言 GLM-4.5（OpenAI兼容接口）
LLM_ZHIPU_LABEL=股票行业深度分析师
LLM_ZHIPU_API_KEY=1728bbcef75949a98e8d6013027e7536.2Dh0tLHP6OfWA2wk
LLM_ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4
LLM_ZHIPU_MODEL=glm-4.5-flash
LLM_ZHIPU_TEMPERATURE=0.2
LLM_ZHIPU_TIMEOUT=60
# 系统提示词已迁移到 backend/prompts/LLM_ZHIPU_SYSTEM_PROMPT.py 文件

# DeepSeek（若无key可先留空或删除整段）
LLM_DEEPSEEK_LABEL=短线技术分析师
LLM_DEEPSEEK_API_KEY=7d02576d2b9c13a647ccc4e34586465a.hlnxicK2PkAmllYl
LLM_DEEPSEEK_BASE_URL=https://open.bigmodel.cn/api/paas/v4
LLM_DEEPSEEK_MODEL=glm-4.5-flash
LLM_DEEPSEEK_TEMPERATURE=0.2
LLM_DEEPSEEK_TIMEOUT=60
# 系统提示词已迁移到 backend/prompts/LLM_DEEPSEEK_SYSTEM_PROMPT.py 文件


# DeepSeek-Plus（若无key可先留空或删除整段）
LLM_PRODUCT_LABEL=行业产品分析师
LLM_PRODUCT_API_KEY=sk-350c1d8b8afe43f3bdfeb47c405b158b
LLM_PRODUCT_BASE_URL=https://api.deepseek.com/v1
LLM_PRODUCT_MODEL=deepseek-chat
LLM_PRODUCT_TEMPERATURE=0.2
LLM_PRODUCT_TIMEOUT=60
# 系统提示词已迁移到 backend/prompts/LLM_PRODUCT_SYSTEM_PROMPT.py 文件

# 邮件与站点配置（本地示例，生产请使用安全存储）
SMTP_HOST=smtp.qq.com
SMTP_PORT=465
SMTP_SECURE=true
SMTP_USER=guangxiangdebizi@qq.com
SMTP_PASS=orccwakajzevdijh
SMTP_FROM_NAME=智能助手
PUBLIC_BASE_URL=http://localhost:5050

# 量化专员（GLM-4.5，使用智谱OpenAI兼容接口）
LLM_QUANT_LABEL=量化专员
LLM_QUANT_API_KEY=7d02576d2b9c13a647ccc4e34586465a.hlnxicK2PkAmllYl
LLM_QUANT_BASE_URL=https://open.bigmodel.cn/api/paas/v4
LLM_QUANT_MODEL=glm-4.5-air
LLM_QUANT_TEMPERATURE=0.2
LLM_QUANT_TIMEOUT=60
# 系统提示词独立文件：backend/prompts/LLM_QUANT_SYSTEM_PROMPT.py

# 可视化助手（Mermaid 与图表）
LLM_VIZ_LABEL=可视化助手
LLM_VIZ_API_KEY=sk-350c1d8b8afe43f3bdfeb47c405b158b
LLM_VIZ_BASE_URL=https://api.deepseek.com/v1
LLM_VIZ_MODEL=deepseek-chat
LLM_VIZ_TEMPERATURE=0.2
LLM_VIZ_TIMEOUT=60
# 系统提示词独立文件：backend/prompts/LLM_VIZ_SYSTEM_PROMPT.py

# 多智能体 TeamAgent 档位（使用 DEEPSEEK 作为底层模型）
LLM_TEAM_LABEL=多智能体(TeamAgent)
LLM_TEAM_KIND=agent
LLM_TEAM_AGENT_FILE=backend/agents/team.yaml
LLM_TEAM_BACKING_PROFILE=DEEPSEEK

# 判别LLM（Oversee）与自动量化路由配置
# 说明：仅将“用户本次提问文本”发给该判别模型，让其回答“是/否”是否为量化需求
# 判别成功→量化则自动切换到 QUANT 档位；失败→回退关键词匹配
OVERSEE_LLM_ENABLED=false
# 可直接复用你的智谱API Key，或另配
Oversee_LLM_APIKEY=7e979ccc055741a187eaddd1dc8d0c59.aLBBFsJXql7QE8qJ
OVERSEE_LLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
OVERSEE_LLM_MODEL=glm-4.5-air
OVERSEE_LLM_TEMPERATURE=0.1
OVERSEE_LLM_TIMEOUT=10
# 可选自定义系统提示词（不填使用内置）
# OVERSEE_LLM_SYSTEM_PROMPT=你是一个严格的路由判别器... 只输出是/否

# 自动路由到量化专员档位（与 LLM_PROFILES 中的ID大小写一致）
AUTO_ROUTE_QUANT=true
AUTO_ROUTE_QUANT_PROFILE_ID=QUANT

# 启用判别LLM调试日志
OVERSEE_LLM_DEBUG=true