# MANHHH é¡¹ç›®æ•°æ®åˆ†æž

## ðŸ“Š åŠŸèƒ½è¯´æ˜Ž

æœ¬æ•°æ®åˆ†æžæ¨¡å—ç”¨äºŽåˆ†æž MANHHH é¡¹ç›®çš„è¿è¥æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š

- âœ… ç”¨æˆ·ç»Ÿè®¡ï¼ˆæ€»æ•°ã€æ–°å¢žã€æ´»è·ƒåº¦ç­‰ï¼‰
- âœ… ä¼šè¯ç»Ÿè®¡ï¼ˆæ€»ä¼šè¯æ•°ã€å¯¹è¯æ•°ã€æ¶ˆæ¯æ•°ï¼‰
- âœ… å·¥å…·è°ƒç”¨ç»Ÿè®¡ï¼ˆå“ªäº›å·¥å…·æœ€å¸¸ç”¨ï¼‰
- âœ… ç”¨æˆ·æé—®è¯äº‘åˆ†æž
- âœ… ç”¨æˆ·å¢žé•¿è¶‹åŠ¿å›¾
- âœ… èŠå¤©æ´»è·ƒåº¦å›¾è¡¨
- âœ… è¯¦ç»†çš„æ•°æ®æŠ¥å‘Š

## ðŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å®‰è£…ä¾èµ–

```bash
pip install matplotlib jieba wordcloud pandas numpy
```

### 2. è¿è¡Œåˆ†æž

```bash
cd /home/ec2-user/AIWebHere/MANHHH-aliyun10/backend/dataanalysis
python analyze.py
```

### 3. æŸ¥çœ‹ç»“æžœ

åˆ†æžç»“æžœä¼šä¿å­˜åœ¨ `output/` ç›®å½•ä¸‹ï¼š

- `analysis_report.txt` - æ–‡æœ¬åˆ†æžæŠ¥å‘Š
- `analysis_data.json` - åŽŸå§‹æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
- `questions_wordcloud.png` - ç”¨æˆ·æé—®è¯äº‘å›¾
- `user_growth.png` - ç”¨æˆ·å¢žé•¿è¶‹åŠ¿å›¾
- `chat_activity.png` - èŠå¤©æ´»è·ƒåº¦å›¾
- `tool_usage.png` - å·¥å…·ä½¿ç”¨ç»Ÿè®¡å›¾

## ðŸ“ è¾“å‡ºç¤ºä¾‹

```
==============================================================
MANHHH é¡¹ç›®æ•°æ®åˆ†æžæŠ¥å‘Š
==============================================================
ç”Ÿæˆæ—¶é—´: 2025-01-15 10:30:00

ã€ç”¨æˆ·ç»Ÿè®¡ã€‘
  æ€»ç”¨æˆ·æ•°: 150
  æœ‰é‚®ç®±ç”¨æˆ·: 120
  é…ç½®äº† Tushare Token: 45
  å¯ç”¨äº† Tushare Token: 30
  æœ€è¿‘7å¤©æ–°å¢ž: 12
  æœ€è¿‘30å¤©æ–°å¢ž: 58
  ç§¯åˆ†å¹³å‡å€¼: 42.5
  ç§¯åˆ†èŒƒå›´: 0 - 100

ã€èŠå¤©ç»Ÿè®¡ã€‘
  æ€»ä¼šè¯æ•°: 3500
  æ€»å¯¹è¯æ•°: 8200
  æ€»æ¶ˆæ¯æ•°: 25600
  æœ€è¿‘7å¤©æ¶ˆæ¯: 1800
  æœ€è¿‘30å¤©æ¶ˆæ¯: 7500
  äººå‡æ¶ˆæ¯æ•°: 170.67

ã€æœ€æ´»è·ƒç”¨æˆ· TOP 10ã€‘
  1. user123: 850 æ¡æ¶ˆæ¯
  2. user456: 620 æ¡æ¶ˆæ¯
  ...

ã€å·¥å…·è°ƒç”¨ç»Ÿè®¡ TOP 10ã€‘
  1. tushare_index_constituents_summary: 320 æ¬¡
  2. search_medical_data: 280 æ¬¡
  ...
```

## ðŸŽ¨ å›¾è¡¨è¯´æ˜Ž

### ç”¨æˆ·æé—®è¯äº‘
- å±•ç¤ºç”¨æˆ·æœ€å¸¸æé—®çš„å…³é”®è¯
- å­—ä½“å¤§å°ä»£è¡¨è¯é¢‘é«˜ä½Ž
- è‡ªåŠ¨è¿‡æ»¤åœç”¨è¯

### ç”¨æˆ·å¢žé•¿è¶‹åŠ¿
- ä¸Šå›¾ï¼šæ¯æ—¥æ–°å¢žç”¨æˆ·æ•°
- ä¸‹å›¾ï¼šç´¯è®¡ç”¨æˆ·å¢žé•¿æ›²çº¿

### èŠå¤©æ´»è·ƒåº¦
- æœ€è¿‘30å¤©çš„æ¯æ—¥æ¶ˆæ¯æ•°
- å¯ä»¥çœ‹å‡ºç³»ç»Ÿä½¿ç”¨çš„æ´»è·ƒæ—¶æ®µ

### å·¥å…·ä½¿ç”¨ç»Ÿè®¡
- æ¨ªå‘æŸ±çŠ¶å›¾å±•ç¤ºå„å·¥å…·è°ƒç”¨æ¬¡æ•°
- æ˜¾ç¤º TOP 15 æœ€å¸¸ç”¨å·¥å…·

## ðŸ”§ è‡ªå®šä¹‰åˆ†æž

å¦‚éœ€è‡ªå®šä¹‰åˆ†æžï¼Œå¯ä»¥ä¿®æ”¹ `analyze.py` è„šæœ¬ï¼š

```python
# ä¿®æ”¹è¯äº‘åœç”¨è¯
stop_words = set(['çš„', 'äº†', ...])

# ä¿®æ”¹å›¾è¡¨æ ·å¼
plt.figure(figsize=(16, 8))  # è°ƒæ•´å¤§å°
plt.colormap('viridis')      # ä¿®æ”¹é¢œè‰²

# æ·»åŠ æ–°çš„ç»Ÿè®¡ç»´åº¦
# åœ¨è„šæœ¬ä¸­æ·»åŠ è‡ªå®šä¹‰ SQL æŸ¥è¯¢å’Œå¯è§†åŒ–
```

## ðŸ“¦ æ–‡ä»¶ç»“æž„

```
dataanalysis/
â”œâ”€â”€ README.md           # æœ¬è¯´æ˜Žæ–‡æ¡£
â”œâ”€â”€ analyze.py          # ä¸»åˆ†æžè„šæœ¬
â”œâ”€â”€ SimHei.ttf          # ä¸­æ–‡å­—ä½“ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰
â””â”€â”€ output/             # è¾“å‡ºç›®å½•
    â”œâ”€â”€ analysis_report.txt
    â”œâ”€â”€ analysis_data.json
    â”œâ”€â”€ questions_wordcloud.png
    â”œâ”€â”€ user_growth.png
    â”œâ”€â”€ chat_activity.png
    â””â”€â”€ tool_usage.png
```

## ðŸ’¡ æ³¨æ„äº‹é¡¹

1. **ä¸­æ–‡å­—ä½“**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨ä¸‹è½½ä¸­æ–‡å­—ä½“ï¼Œå¦‚ä¸‹è½½å¤±è´¥ä¼šå°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
2. **æ•°æ®éšç§**ï¼šåˆ†æžç»“æžœä¸­ä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼ˆå¯†ç ã€Tokenç­‰ï¼‰
3. **æ€§èƒ½**ï¼šå¤§æ•°æ®é‡æ—¶åˆ†æžå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ
4. **å®šæœŸè¿è¡Œ**ï¼šå»ºè®®å®šæœŸè¿è¡Œä»¥è·Ÿè¸ªé¡¹ç›®å‘å±•è¶‹åŠ¿

## ðŸ”„ å®šæ—¶åˆ†æž

å¯ä»¥ä½¿ç”¨ cron å®šæ—¶è¿è¡Œåˆ†æžï¼š

```bash
# ç¼–è¾‘ crontab
crontab -e

# æ·»åŠ æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œåˆ†æž
0 2 * * * cd /home/ec2-user/AIWebHere/MANHHH-aliyun10/backend/dataanalysis && python analyze.py >> analysis.log 2>&1
```

